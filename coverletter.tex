{\noindent \normalsize \bf Dear SIGMOD Chair and Referees: }

\vspace{.5em}

We thank the reviewers and chair for the very helpful feedback on our paper. 
We addressed all of the concerns and included references to the revised text. 
To summarize the major changes:

\begin{enumerate}
\item Sections 1 and 2 clarify the relationship between \sys and related work in data cleaning that applies machine learning (e.g., \cite{gokhale2014corleone, DBLP:journals/pvldb/YakoutENOI11, yakout2013don}).

\item In Section \ref{dmodel}, we formalize the definition of dirty data and the data cleaning model used in this work.

\item In Section \ref{statements}, we provide problem statements for the two subproblems addressed in this work.

\item Section \ref{arch} presents a revised system architecture that first emphasizes the essential components for correctness, and then highlights optional optimizations. 

\item Section \ref{s:usecase} presents a running example that is referenced in each technical section (Examples \ref{archex}, \ref{upex},\ref{detex1},\ref{detex2},\ref{estex}).

\item We include references to the related work suggested by the reviewing committee \cite{whang2014incremental, papenbrock2015progressive, gruenheid2014incremental, DBLP:journals/pvldb/YakoutENOI11, yakout2013don, heise2014estimating}.

\end{enumerate}
Below we address each reviewer comment in detail:

\vspace{0.5em}

\subsection*{Meta Review Details} 
Machine learning has been studied as a technique to improve the efficiency and reliability of data cleaning~\cite{yakout2013don,gokhale2014corleone}.
In these approaches, machine learning is used to train a Data Cleaning Model (DCM) that learns to predict the value of an incorrect or missing attribute given data that are previously cleaned or known to be clean.
For example, Yakout et al. train a statistical model that evaluates the likelihood of a proposed replacement value \cite{yakout2013don}.
When humans are involved, machine learning can facilitate progressive cleaning by gradually learning a model that predicts the results of the expensive human queries \cite{gokhale2014corleone, DBLP:journals/pvldb/MozafariSFJM14, DBLP:journals/pvldb/YakoutENOI11}.

%This use case leverages clean data to estimate the accuracy of a future repair on dirty data.
%On the other hand, Gokhale et al. \cite{gokhale2014corleone} use machine learning to
%scale crowdsourced data cleaning by learning rules from a small set of examples.
%Crowdsourcing is often expensive and impractical for large datasets. 
%This approach can be coupled with active learning to query a human (or humans) only when the statistical model indicates uncertainty.

\sys addresses the problem of statistical analysis after data cleaning.
We call such models Downstream Statistical Models (DSMs) to contrast with the DCMs in prior work.
An example of a DSM is a movie recommender system that collects dirty user preference data resulting in error-prone predictions.
The DSM is independent of the errors manifest in the data.
The DSM problem is more general than the DCM problem with a broader class of allowed statistical models.
Furthermore, training a DSM on a mix of dirty and clean data can lead to arbitrarily incorrect results (Figure \ref{update-arch1}), and this requires a new algorithm to allow for progressive cleaning while preserving correctness.
%Due to the generality of a DSM, small samples of clean data may not result in a meaningful model.
Finally, we propose several novel extensions to active learning, including dirty data detection and estimation, to clean data that maximally benefit a DSM.
Response \textbf{M5} addresses each of the differences in more detail.


\vspace{0.5em}

\noindent\noindent \textbf{M1. There should be a formal vocabulary introduced early on. The exact idea of ``dirty" here can be hard to follow: what is the exact error type(s) that the system is intended to clean?}

\vspace{0.5em}

We thank the reviewers for this important feedback and clarified that our system applies to data cleaning operations that can be represented as record-by-record mappings.
%This model is sufficiently expressive for our experiments and a number of real-world dirty data scenarios such as making attribute values consistent and missing value filling.
We hope to explore additional data cleaning models that include record deduplication or schema transformations in future work.
We added the following clarification to Section \ref{dmodel}:

\emph{\sys supports data cleaning operations that can be represented as record-by-record transformations.
Formally, there exists a function (implemented via human or algorithm) that when given a dirty record, it will return a unique clean record.
This does not cover errors that simultaneously affect multiple records such as record duplication or schema transformation problems.
We represent this operation as $C(\cdot)$ which can be applied to a record $r$ to recover $r_{clean} = C(r)$.
Therefore, for every $r \in R_{dirty}$ there exists a unique $r' \in R_{clean}$.
We assume that there is a featurization $F(\cdot)$ which is defined over both $R_{dirty}$ and $R_{clean}$ and maps records to tuple of vectors in $(\mathbb{R}^d, \mathbb{R}^l)$ corresponding to features and labels.
So each record corresponds to one training example in the downstream model.}

\vspace{0.5em}

\noindent\textbf{M2. Sections 5-7 are the technical core of the paper, and appear formal at the expense of aiding understanding. They appear to implement something that resembles active learning or bootstrapping, except inside the gradient descent loop. The motivation of some of this is not clear; is it necessary to integrate with the gradient descent? This is not how most active learning methods are implemented. Is it possible to implement these approaches in a way that is orthogonal to the SGD algorithm? The current writeup entangles some of these design choices.} 

We have revised the technical sections of the paper to improve readability.
In Section \ref{correctness}, we present two straight-forward integrations of progressive data cleaning and predictive modeling. 
We explain their limitations and describe how these solutions can result in error-prone models.
To address these limitations, we describe two subproblems: (1) the correctness problem of how to update a dirty model after cleaning and (2) the efficiency problem of how to prioritize cleaning using the downstream model. 
Section \ref{statements} independently formalizes the two problems without reference to Stochastic Gradient Descent.

In Section \ref{model-update}, we propose one solution to problem (1) which updates the model with newly cleaned data using a gradient step.
This can be analyzed as a Stochastic Gradient Descent algorithm, which converges to the true optimum with monotonically decreasing expected error if the gradient steps are unbiased.
We revised the presentation of this section to be independent of the sampling distribution used to select which data to clean.

In Section \ref{dist-samp}, we describes a basic solution to problem (2).
The problem is to find a sampling distribution that maximally reduces the expected error
at each iteration.
While, the solution is derived using optimality w.r.t SGD, this sampling distribution is still beneficial to techniques other than SGD.
The derived optimal distribution is not realizable in practice since it requires knowing the cleaned record value.
Section \ref{dgsample} proposed one solution where the dirty value of the record can be used instead.
Together Section \ref{model-update} and \ref{dist-samp}, provide a minimum viable system that addresses problem (1) and (2).

Section \ref{opti} describes optimizations that improve the convergence rate of the system.
We describe a number of cases when these optimizations are possible.
Our experiments (Section \ref{eval}) evalaute all of these design decisions.

\vspace{0.5em}

\noindent\textbf{M3. In general, the distinction between an ``architecture" and an ``algorithm that fits into the architecture" is quite unclear. The problem with SGD/Active Learning above is one example.}

We have revised the paper to separate problem statements (Section \ref{statements}) and system architecture (Section \ref{arch}), which was part of the confusion in the initial submission.
The architecture in Section \ref{sysover} describes how each of the components fit together and the data flows of the system.
We describe these components in a way that is independent of our algorithmic solutions with Stochastic Gradient Descent and Active Learning.
The new architecture would apply even if the model update problem was addressed with a different algorithm.
We first clarify essential components of the architecture that are needed for a minimum viable solution to problem (1) and (2), 
Then, we highlight the optional components which optimize the execution.
%We also clearly identify the user inputs in Section \ref{uinp}.

\vspace{0.5em}

\noindent\textbf{M4. The paper, and especially the technical sections, would benefit enormously from a detailed running example showing how the algorithm works}

We have added a number of examples at the end of each of the technical sections. Section 4 (Architecture) ends with an intuitive end-to-end running example without technical details (Example \ref{archex}).
Section 5 (Update Problem) ends with an SVM example of how updates are propagated and calculated (Example \ref{upex}).
Section 7.1 (Detection) contains two examples for how the two different types of detectors can be used (Examples \ref{detex1} and \ref{detex2}).
Section 7.2 (Estimation) ends with an example summarizing how linearization could be applied to SVM estimation.

\vspace{0.5em}

\noindent\textbf{M5. Some connections to related work that combines machine learning and data cleaning should be made. See the other reviewers' comments.}

We highlight related work in the background section (Section \ref{alrw}):

\emph{Machine learning can be used as a technique to improve the efficiency and/or reliability of data cleaning\cite{yakout2013don,gokhale2014corleone}.
For example, Yakout et al. train a statistical model that evaluates the likelihood of a proposed replacement value \cite{yakout2013don}.
Another application of machine learning is value imputation, where a missing value is predicted based on those records without missing values.
Machine learning is also increasingly applied to make automated repairs more reliable with human validation \cite{DBLP:journals/pvldb/YakoutENOI11}.
Human input is often expensive and impractical to apply to entire large datasets.
Machine learning can extrapolate rules from a small set of examples cleaned by a human (or humans) to uncleaned data \cite{gokhale2014corleone, DBLP:journals/pvldb/YakoutENOI11}.
This approach can be coupled with active learning \cite{DBLP:journals/pvldb/MozafariSFJM14} to learn an accurate model with the fewest possible number of examples, and intuitively, this means
query a human only when the statistical model indicates uncertainty.\\
The common feature of these approaches is a Data Cleaning Model (DCM) that learns to predict the value of an incorrect or missing attribute given data that are previously cleaned or known to be clean.
In contrast, \sys addresses the problem of statistical analysis, in the form of Machine Learning, on clean data.
We call such models Downstream Statistical Models (DSMs) to contrast them with the DCMs in prior work.
An example of a DSM is a movie recommender system that collects dirty user preference data resulting in error-prone predictions.
The DSM is independent of the errors manifest in the data and is specified by the user.
The DSM problem is more general than the DCM problem with a broader class of allowed statistical models.
There are two key challenges in applying data cleaning before a DSM: (1) statistical validity, and (2) efficiency. 
\sys addresses both of these challenges using an incremental update framework that ensures correctness of intermediate results and several novel extensions to active learning, including dirty data detection and estimation, to clean data that maximally benefit a DSM.}

\vspace{0.5em}
Our related work section~(Section \ref{rw}) highlights the suggested references to progressive data cleaning:

\emph{When data cleaning is expensive, it is desirable to apply it \textbf{progressively}, where analysts can inspect early results with only $k \ll N$ records cleaned.
Progressive data cleaning is a well studied problem especially in the context of entity resolution \cite{altowim2014progressive, whang2014incremental, papenbrock2015progressive, gruenheid2014incremental}.
Prior work has focused on the problem of designing data structures and algorithms to apply data cleaning progressively.
This is challenging because many data cleaning algorithms require information from entire relations.
However, over the last 5 years a number of new results have expanded the scope of progressive data cleaning~\cite{mayfield2010eracer, DBLP:journals/pvldb/YakoutENOI11, yakout2013don}.
\sys explores the statistical implications of using progressive data cleaning before high-dimensional predictive modeling.}

\vspace{0.5em}

\emph{SampleClean\cite{wang1999sample} applies data cleaning to a sample of data, and estimates the results of aggregate queries.
Sampling has also been applied to estimate the number of duplicates in a relation \cite{heise2014estimating}. 
Similarly, Bergman et al. explore the problem of query-oriented data cleaning \cite{DBLP:conf/sigmod/BergmanMNT15}, where given a query, they clean data relevant to that query. 
Existing work does not explore cleaning driven by the downstream machine learning models studied in this work.}

\subsection*{Review 1 Details} 

\noindent\textbf{R1.1: At first, the problem seems a bit too specialized. The abstract is too loaded with technical terms and a turn-off. This is then mitigated in the introduction. \\
As mentioned above, the abstract is (to me) overly technical and did not make me curious. I did not know off the bat what a convex loss model is, what importance sampling is, etc.}

\noindent We revised the abstract to be more accessible:

\emph{Dirty data, including missing, incorrect, or inconsistent values, is an important challenge in data analytics.
Predictive models, such as regression and classification, are increasingly popular forms of data analytics and can be highly sensitive to dirty data.
Although error can be mitigated through data cleaning, it is often very time consuming.
This paper explores techniques to train accurate models without having to clean the entire dataset.
The challenge is that models trained on partially cleaned data can be arbitrarily incorrect requiring a new algorithm for incrementally updating results given newly cleaned data.
We also design sampling algorithms that leverage knowledge about downstream statistical models to prioritize cleaning those records likely to affect the results.
We focus on a popular class of models called convex loss models (e.g., linear regression and SVMs).
The key insight of our framework is that data cleaning can be applied simultaneously with incremental optimization allowing for progressive cleaning while preserving provable properties.
Evaluation on four real-world datasets suggests that for a fixed cleaning budget, \sys returns more accurate models than uniform sampling and Active Learning when corruption is systematic and sparse.}

\vspace{0.5em}

\noindent\textbf{R1.2: Poor embrace of the duplicate detection problem (see details below). Your model of the cleaner seems to preclude any duplicate detection, which certainly cannot happen on individual records. Also you extension for a set of record does not fit the problem of duplicate detection. This is in contrast, for instance, to your ER example in the second column of that page. Appendix A.1 is misleading here, as you mention with Example 7 ``in entity resolution problems..." but do not actually address that problem in the example. Fixing some common inconsistency is not entity resolution.}

We apologize for the confusing terminology and have revised our paper to clarify that we do not address record-level deduplication.
We intended to bring attention to the fact that some types of attribute level inconsistencies are addressed in similar ways to record deduplication.
For example, in our experimental dataset, the inconsistencies ``Pfizer Inc.", ``Pfizer Incorporated", and ``Pfizer" can be addressed using a blocking and matching procedure similar to that used in record deduplication.
That said, we have removed references to entity resolution and described our data cleaning model in more precise terms.

\vspace{0.5em}

\noindent\textbf{R1.3: Cheated by using a narrower font than required. Will have trouble with camera ready copy if publisher insists on proper font.\\
- I would not use ``overview" as a verb...
- 3.2: the detector select -> the detector selects
- 4.3: Wrong quotation marks around ``learning".
- QED symbols on page 8 are ugly when placed directly after formula. 
- References need a clean up. Just as an example: Venue is missing for [24], year is mentioned 3 times for [8], [11], etc. Page numbers appear sporadically.}

\noindent We have addressed all of the formatting and copy editing issues.

\vspace{0.5em}

\noindent\textbf{R1.4:There is some related work specifically addressing progressive/incremental entity resolution. You might want to point your readers to this.
\\E.g.
\\- Incremental entity resolution on rules and data, Whang et al. VLDB Journal 2014
\\- Progressive duplicate detection, Papenbrock et al., TKDE 2015
\\- Incremental record linkage, Gruenheid et al., PVLDB 2014
\\- Another work that is related is ``Estimating the Number and Sizes of Fuzzy-Duplicate Clusters" by Heise et al. CIKM 2014, which also incrementally cleans samples of data to predict in this case the number of record matches.}

Thank you for highlighting these references, and we have included them in our related work~(see response \textbf{M5}).

\vspace{0.5em}

\noindent\textbf{- Page 1, last paragraph in column 1 reads as if reference to [3] is a reaction to the work referenced in the previous sentence, i.e., the term ``remains" is misleading.
- I did not quite understand the short paragraph on crowd-sourcing. Why is this even relevant?
 I believe it would suffice to simply state that cleansing is expensive...}

We appreciate the thorough feedback and have tightened up the writing in the introduction. In particular, we have consolidated the motivation to a single paragraph describing the expense of data cleaning. We include a single sentence reference to related work on crowdsourcing/human-guided data cleaning which we believe is relevant due to the use of active learning.


\subsection*{Review 2 Details}

\noindent\textbf{R2.1: The definition of ``clean data" is imprecise and not clear. It appears that ``cleaning" in this system refers to entity resolution, cleaning w.r.t. dependencies, and possibly other actions as needed by the application. This makes it difficult to gauge overall accuracy when there are different interpretations of cleanliness. It is not clear how entity resolution and cleaning w.r.t. dependencies can be done holistically.}

We addressed this concern in response \textbf{M1}.

\vspace{0.5em}

\noindent\textbf{R2.2: The paper describes a problem setting focused on modelling the iterative cleaning process rather than actual data management problems. The paper may be better suited at an ML venue.}

Over the last 5 years a number of new results have expanded the scope of progressive and interactive data cleaning~\cite{mayfield2010eracer, DBLP:journals/pvldb/YakoutENOI11, yakout2013don, altowim2014progressive, whang2014incremental, papenbrock2015progressive, gruenheid2014incremental}.
However,  it turns out that the straight-forward application of existing progressive data cleaning methods can lead to error-prone and misleading results (Section \ref{correctness}).
Recognizing that data analytics is increasingly moving towards statistical modeling, \sys presents an initial exploration of this problem.  

\vspace{0.5em}

\noindent\textbf{R2.3: Missing references to related work on interactive data cleaning. For the comparative evaluation, 2/3 techniques are ML based techniques, not interactive data cleaning systems. See D2.\\
D2: Data cleaning systems have also considered interactive engagement with the user and the application of ML techniques. 
i) Mohamed Yakout, Laure Berti-Equille, Ahmed K. Elmagarmid. Don't be SCAREd: use SCalable Automatic REpairing with maximal likelihood and bounded changes. SIGMOD Conference 2013: 553-564
ii) Mohamed Yakout, Ahmed K. Elmagarmid, Jennifer Neville, Mourad Ouzzani, Ihab F. Ilyas.
Guided data repair. PVLDB 4(5): 279-289 (2011).
}

In Section \ref{alrw}, we contrast two applications of machine learning in data cleaning: Data Cleaning Models (DCMs) and Downstream Statistical Models (DSMs).
A Data Cleaning Model (DCM) is a model that learns to predict the value of an incorrect or missing attribute given data that are previously cleaned or known to be clean.
DCMs are used to improve the efficiency or reliability of data cleaning by: extrapolating rules from a small number of cleaned examples, estimating likelihoods that a repair is accurate, or numerical value imputation.
In contrast, the DSM problem is an analyst-specified model to be trained after data cleaning.
The DSM problem is more general, and as a result, a number of the optimizations used in the DCM literature do not apply.
Furthermore, training a DSM on a mix of dirty and clean data can lead to arbitrarily incorrect results (Figure \ref{update-arch1}), and this requires a new algorithm to allow for progressive cleaning while preserving correctness.
\sys is an estimation framework for DSMs using existing data cleaning methods and not a new data cleaning algorithm.
In our experiments (Section \ref{comp}), we illustrate the relative contribution of different components in \sys, which benchmarks the entire framework against a minimal solution that still provides correct results.


\vspace{0.5em}

\textbf{R2.4: Sampling is an important part of the framework and influences the accuracy of the cleaning. Yet, there is little discussion on sampling rate, or how a sample is chosen.}

We revised Sections 6 and 7 to be more precise about the sampling.
Section 6 describes sampling without estimation or detection:

\emph{The model update received a sample with probabilities $p(\cdot)$.
\sys uses a sampling algorithm that selects the most valuable records to clean with higher probability. }

\vspace{0.5em}

Section 7 describes how sampling can be improved with estimation and detection and intuition on why those optimizations improve result accuracy.

\vspace{0.5em}

\textbf{R2.5: An end-to-end running example in Section 5 is needed to highlight the intuition of the cleaning process.}

We addressed this point with a number of examples (see response \textbf{M4}).


\vspace{0.5em}


\subsection*{Review 3 Details}
\noindent\textbf{R3.1: The authors do not distinguish between the system architecture and the individual issues that they are presenting.}

Response \textbf{M3} describes several revisions to the architecture including: separating problem formalization and architecture, discussing the data flow rather than the algorithms, and highlight essential components for correctness versus optimizations.

\vspace{0.5em}

\noindent\textbf{R3.2: The paper uses lots of definitions, and a multitude of that do not necessarily contribute to readability.
Without being an expert in the field, I found it extremely difficult to follow the paper as it touches upon multiple problems at the same time: data cleaning, model training, convex analytics, etc., uses definitions, notation and lots of examples that did not allow me to have a global understanding of the work.\\
I would prefer to have a more focused paper on one of these aspects that has concrete goals and then, having an overview of the architecture of the system as a small section. I believe that the architecture should not be the focus and the skeleton of this paper. Instead, I believe that the authors could focus on the individual problems.}

We have discussed a number of specific textual revisions in response \textbf{M2} and \textbf{M3}. Here are a list of other revisions to improve the readability:

\begin{enumerate}
\item We have expanded the background section to provide a more detailed setup and context to the problem.
\item Our problem formulation is now divided into two subproblems: (1) correctness, and (2) efficiency.
\item We revised the technical sections to first present a minimum viable solution that addresses the two subproblems (Section \ref{model-update} and Section  \ref{dist-samp}).
\item The next section (Section \ref{opti}) describes optional optimizations that can be applied in a number of practical cases.
\item Detailed derivations are now in the appendix, and the additional space has been used for three new examples in the technical sections (Sections \ref{model-update}-\ref{opti}).
\end{enumerate}
