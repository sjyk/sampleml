\section{Approximating the Optimal Distribution}\label{sampling}
This section describes our solution to problem of constructing and maintaining an inexpensive estimate of the optimal sampling distribution.

\subsection{Challenges}
The optimal sampling distribution is dependent on a value that we cannot know without data cleaning $\nabla\phi(x^{(clean)}_i,y^{(clean)}_i,\theta^t)$.
One way to approximate this distribution is to learn a function $e(\cdot)$ mapping $(x_{clean}, y_{clean})$, based on the data that we have cleaned.
Suppose, we use a regression technique based on the previous data.
This is a high-dimensional regression problem which may have to learn a very complicated relationship between dirty and clean data.
The biggest challenge with such an estimator is the cold start problem, where if we have cleaned a very small number of errors, the estimator will be inaccurate. 
In \sys, we want to be able to make as much progress as possible in the early iterations so this technique may not work.
In general, the more complex the model, the more data it will require before sufficient accuracy.
We take an alternative approach, where we try to exploit what we know about data cleaning to produce an estimate for groups of similarly corrupted records.

\subsection{Error Decoupling}
We come back to the insight of the last section, where error detection is often much easier than error repair.
For many types of data error, we can return a subset of corrupted attributes and in turn a subset of features that are corrupted; all without cleaning the data.
Recall, that when we formalized the error detection problem, we ensured that associated with each $r \in R_{dirty}$ is a set of errors $e_r$ which is a set that identifies a set of corrupted columns.
We will show how we can use this property to construct a coarse estimate of the clean value.
The main idea is that if we can calculate average changes for each feature, then given an uncleaned (but dirty) record, we can add these average changes to correct the gradient.

\begin{example}
Consider our EEG dataset with multiple types of errors. 
Suppose the electrical signals for some records are corrupted with missing data and the patient data for other records are corrupted with inconsistency problems. 
Each training example will have a set of corrupted features (i.e., $\{1,2,6\}$, $\{1,2,15\}$).

Suppose that we have just cleaned the records $r_1$ and $r_2$ represented as tuples with their corrupted feature set: ($r_1$,$\{1,2,3\}$), ($r_2$,$\{1,2,6\}$).
Then, we have new record ($r_3$,$\{1,2,3,6\}$). 
We want to be able to use the cleaning results from $r_1,r_2$ to estimate the gradient in $r_3$.
\end{example}

Let us formalize this intuition.
Instead of computing the actual gradient with respect to the 
true clean values, let us compute the conditional expectation given that a set of features and labels $f_r$ are corrupted:
\[
p_i \propto \mathbb{E}(\nabla\phi(\theta_{(t)}^Tx_{clean},y_{clean}) \mid f_r)
\]
What we mean by corrupted features is that:
\[
i \notin f_r \implies x_{clean}[i] - x_{dirty}[i] = 0
\]
\[
i \notin f_r \implies y_{clean}[i] - y_{dirty}[i] = 0
\]
So basically, if most of the features are correct, it would seem like the gradient is only
incorrect in one or two of its components.
The problem is that the gradient $\nabla\phi(\cdot)$ can be a very non-linear function of the features that couple features together.
For example, let us look at the gradient for linear regression:
\[
\nabla\phi(x,y,\theta) = (\theta^Tx - y)x
\]
We see that it is not possible to isolate the effect of a change of one feature on the gradient.
Decoupling allows us to treat errors conditioned on each feature independently.
Alternative techniques such as taking the average change the gradient, without this property, would require to condition on every distinct set of corrupted features which can be combinatorially large. 

\subsection{Linear Approximation}
We can approximate the gradient in such a way that we can do this.
This approximation represents a linearization of the errors.
We can take the expected value of the Taylor series expansion around the dirty value.
If $d$ is the dirty value and $c$ is the clean value, the Taylor series approximation for a function $f$ is given as follows:
\[
f(c) = f(d) + f'(d)\cdot(d-c) + ...
\]
If we ignore the higher order terms, we see that the linear term $f'(d)\cdot(c-d)$ decouples the features.
We only have know the change in each feature to estimate the change in value.
In our case the function $f$ is the gradient $\nabla\phi$.
So, the resulting linearization is:
\[
\nabla\phi(\theta^Tx_{clean},y_{clean}) \approx \nabla\phi(\theta^Tx,y) + \frac{\partial}{\partial X}\nabla\phi(\theta^Tx,y)\cdot (x - x_{clean}) \]
\[+ \frac{\partial}{\partial Y}\nabla\phi(\theta^Tx,y)\cdot (y - y_{clean})
\]
When we take the expected value:
\[
\mathbb{E}(\nabla\phi(\theta^Tx_{clean},y_{clean})) \approx \nabla\phi(\theta^Tx,y) + \frac{\partial}{\partial X}\nabla\phi(\theta^Tx,y)\cdot \mathbb{E}(\Delta x) \]
\[+ \frac{\partial}{\partial Y}\nabla\phi(\theta^Tx,y)\cdot \mathbb{E}(\Delta y)
\]
So the resulting estimation formula takes the following form:
\[
\approx \nabla\phi(\theta^Tx,y) + M_x \cdot \mathbb{E}(\Delta x) + M_y \cdot \mathbb{E}(\Delta y) 
\]
Recall that we have a $d$ dimensional feature space and $l$ dimensional label space.
Then, $M_x = \frac{\partial}{\partial X}\nabla\phi$ is an $d \times d$ matrix, and $M_y = \frac{\partial}{\partial Y}\nabla\phi$ is a $d \times l$ matrix.
Both of these matrices are computed with respect to dirty data, and we will present an example.
$\Delta x$ is a $d$ dimensional vector where each component represents a change in that feature and $\Delta y$ is an $l$ dimensional vector that represents the change in each of the labels. 

Let us return to the linear regression example, where the gradient is:
\[
\nabla\phi(x,y,\theta) = (\theta^Tx - y)x
\]
It we take the partial derivatives with respect to x $M_x$ is:
\[
M_x[i,i] = 2x[i] + \sum_{i \ne j} \theta[j]x[j] - y 
\]
\[
M_x[i,j] = \theta[j]x[i]
\]
Similarly $M_y$ is:
\[
M_y[i,1] = x[i] 
\]
In the appendix, we describe the matrices for common convex losses \reminder{TR}.

\subsection{More Accurate Early Error Estimates}
We can give some intuition on why the linearization actually avoids amplifying estimation error.
If we consider the linear regression gradient:
\[
\nabla\phi(x,y,\theta) = (\theta^Tx - y)x
\]
We can rewrite this as a vector in each component:
\[
g[i] = \sum_{i} x[i]^2-x[i]y + \sum_{j \ne i} \theta[j]x[j]
\]
We see that this function is already mostly linear in $x$ except for the one quadratic term.
However, this one quadratic term has potential to amplify errors.
Consider two estimates:
\[
f(x+\epsilon) = (x+\epsilon)^2 = x^2 + 2x\epsilon + \epsilon^2
\]
\[
f(x+\epsilon) \approx f(x) + f'(x)(\epsilon) = x^2 + 2x\epsilon
\]
The only difference between the two estimates is the quadratic $\epsilon^2$, if $\epsilon$ is highly uncertain random variable then the quadratic dominates.
Since we are using an average which is a coarse grained estimate high error is unavoidable.
The bottom estimate while a potentially biased approximation avoids amplifying this error.
We evaluate our technique in Section \ref{est} against alternatives, and we find that indeed we provide more accurate estimates for a small number of samples cleaned.
When the number of cleaned samples increases the alternative techniques are comparable.

\subsection{Maintaining Decoupled Averages}
This linearization allows us to maintain per feature (or label) average changes and use these changes to center the optimal sampling distribution around the expected clean value.
We know how to estimate $\mathbb{E}(\Delta x)$ and $\mathbb{E}(\Delta y)$.
\begin{lemma}[Single Feature]
For a feature $i$, we average all records cleaned that have an error for that feature, weighted by their sampling probability:
\[
\bar{\Delta}_i = \frac{1}{NK}\sum_{j=0}^K (x[i]-x_{clean}[i])\times \frac{1}{p_j}
\]
Similarly, for a label $i$:
\[
\bar{\Delta}_i = \frac{1}{NK}\sum_{j=0}^K (y[i]-y_{clean}[i])\times \frac{1}{p_j}
\]
\end{lemma}

Then, it follows, that we can aggregate the $\bar{\Delta}_i$ into a single vector:
\begin{lemma}[Delta vector]
Let $\{1..,i,...,d\}$ index the set of features and labels.
For a record $r$, the set of corrupted features is $f_r$.
Then, each record $r$ has a d-dimensional vector $\Delta_r$ which is constructed as follows:
\[
 \Delta_r[i] = \begin{cases} 0 & i \notin f_r \\ 
\bar{\Delta}_i & i \in f_r
\end{cases} 
\]
\end{lemma}

With the above theorem, we finally have an approximation to our sampling weights: 
\[p_{r}\propto\|\nabla\phi(x,y,\theta^{(t)}) + M_x \cdot \Delta_{rx} +  M_y \cdot \Delta_{ry}\|\]


