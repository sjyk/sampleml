\section{System Architecture}\label{arch}
This section presents an overview of the \sys architecture.
\sys addresses two challenges in model training after progressive cleaning: (1) the methodological problem of reliable analysis or the \emph{Update Problem}, and (2) the algorithmic problem of using information from the model to prioritize data cleaning which we call the \emph{Optimization Problem}.
The \sys architecture in Figure \ref{sys-arch} describes an end-to-end system implementing our solutions to these two challenges.

\subsection{User Input}\label{uinp}
\sys provides reliable model estimates when progressive data cleaning and machine learning are applied together.
Both of these components are user-specified and \sys is an estimation framework that wraps around them.
To use \sys, the user provides the following:

\noindent\textbf{Convex Model and Initialization. } The user provides a predictive model specified as a convex loss optimization problem, a function $F(\cdot)$ that featurizes the data, and an initial model $\theta^{(d)}$ trained on the dirty data. 

\vspace{0.25em}

\noindent\textbf{Cleaning Function. } The data cleaning is specified as a function $C(\cdot)$ that maps dirty records to clean records. This paper focuses on a record-by-record cleaning model where the function $C$ is applied to a record and produces the clean record:
\[
S_{clean} = \{C(r) : \forall r \in S_{dirty}\}
\]
This allows for uniform measure of the performance of \sys in terms of model error as a function of sample size. The record-by-record cleaning model is not a fundamental restriction of this approach, and in the extensions (Section \ref{set-of-r}), there is a discussion on a compatible ``set of records" cleaning model. Consider the case where an analyst finds a dirty record, and is able to fix all records (possibly outside the sample) the with same error throughout the dataset efficiently.

\vspace{0.25em}

\noindent\textbf{Specifying a Budget. } At initialization, there are two hyperparameters to set, the cleaning budget $k$ and the batch size $b$ (the number of iterations is $T = \frac{k}{b}$).
We discuss how to set $b$ and the tradeoffs in setting a larger or smaller $b$ in Section \ref{model-update}.

\vspace{0.25em}

\noindent\textbf{Detector (Optional Section \ref{det}). } Optionally, \sys integrates with dirty data detection rules $D(\cdot)$ which selects the set of likely corrupted records from $R$.
If one is not provided, \sys starts by treating all of the data as dirty and tries to learn a detector as data are cleaned.
 The detector select a candidate set of dirty records $R_{dirty} \subseteq R$. There are two techniques to do this: (1) an \emph{a priori} case, and (2) and an adaptive case. 

\subsection{Problem 1. Update Problem}\label{updp}
Let $R_{dirty} \subseteq R$ be the subset of records that are dirty, and $S_{clean}$ is a cleaned sample (possibly non-uniform) of the records $R_{dirty}$.
In the model update problem, \sys applies an update to the dirty model $\theta^{(d)}$, based on some newly cleaned data $S_{clean}$, to return $\theta^{new}$.
Of course, these updates will have some error between the updated model and the true model $\theta^{(c)}$ (if the entire dataset is cleaned):
\[
error(\theta^{new}) = \| \theta^{new} - \theta^{(c)} \|
\]
We call the update algorithm ``reliable" if the expected error is upper bounded by a monotonically decreasing function $f$ of the amount of cleaned data:
\[
\mathbb{E}(error(\theta^{new})) = O(f(\mid S_{clean} \mid))
\]
and is also upper bounded by a monotonically increasing function of the initial error:
\[
\mathbb{E}(error(\theta^{new})) = O(g(\| \theta^{(d)} - \theta^{(c)} \|))
\]
Intuitively, more cleaning and less initial error should imply more accuracy.
In Section \ref{model-update}, we describe how we can incrementally maintain the model given some cleaned data $S_{clean}$ using Stochastic Gradient Descent (SGD).
This procedure will avoid the pitfalls of dimensionality and Simpson's paradox.

\subsection{Problem 2. Optimization Problem}\label{optp}
\sys optimizes the execution of the updates by carefully selecting $S_{clean}$.
The optimization problem is to select $S_{clean}$ such that the expected error $\mathbb{E}(error(\theta^{new}))$ is minimized.
\sys uses previously cleaned data to estimate the value of data cleaning on new records.
Then it draws a sample of records $S_{dirty} \subseteq R_{dirty}$. This is a non-uniform sample where each record $r$ has a sampling probability $p(r)$ based on the estimates.
We derive the optimal sampling distribution for the SGD updates, and show how the theoretical optimal can be approximated.

\subsection{Overview}
\sys is a framework that implements solutions to the update and optimization problems.
Figure \ref{sys-arch} describes the main components of this architecture.
To summarize in pseudocode:
\begin{enumerate}[leftmargin=1em]\scriptsize\sloppy
\item \texttt{Init(dirty\_data, cleaned\_data, dirty\_model, batch, iter)}
\item For each t in $\{1,...,T\}$
\begin{enumerate}
	\item \texttt{dirty\_sample $=$ Sampler(dirty\_data, sample\_prob, detector, batch)}
	\item \texttt{clean\_sample $=$ Cleaner(dirty\_sample)}
	\item \texttt{current\_model $=$ Update(current\_model, sample\_prob, clean\_sample)}
	\item \texttt{cleaned\_data = cleaned\_data + clean\_sample}
	\item \texttt{dirty\_data = dirty\_data - clean\_sample}
	\item \texttt{sample\_prob $=$ Estimator(dirty\_data, cleaned\_data, detector)}
	\item \texttt{detector $=$ DetectorUpdater(detector, cleaned\_data)}
\end{enumerate}
\item \texttt{Output: current\_model}
\end{enumerate}

Here is an example application of \sys:
\begin{example}\label{archex}
The analyst first trains an SVM model on the dirty data ignoring the effects of the errors resulting in a model $\theta^{(d)}$.
She decides that she has a budget of cleaning $100$ records, and decides to clean the 100 records in batches of 10 (set based on how fast she can clean the data, and how often she wants to see an updated result).
She initializes \sys with $\theta^{(d)}$.
\sys samples an initial batch of 10 records.
She manually cleans those records by merging similar drug names, making corporation names consistent, and fixing incorrect labels.
After each batch, the model is updated with the most recent cleaning results $\theta^{(t)}$.
The model improves after each iteration.
After $t=10$ of cleaning, the analyst has an accurate model trained with 100 cleaned records but still utilizes the entire dirty data.
\end{example}

\iffalse
\subsection{Challenges and Formalization}
We highlight the important components and formalize the research questions explored in this paper. 

\vspace{0.5em}

\noindent\textbf{Detector (Section \ref{det}). } The first challenge in \sys is dirty data detection. In this step, the detector selects a candidate set of dirty records $R_{dirty} \subseteq R$. There are two techniques to do this: (1) an \emph{a priori} case, and (2) and an adaptive case. In the \emph{a priori} case, the detector knows which data is dirty in advance. In the adaptive case, the detector learns classifier based on previously cleaned data to detect corruption in uncleaned data.

\vspace{0.5em}



\vspace{0.5em}



\vspace{0.5em}

\noindent\textbf{Update (Section \ref{model-update}). } This step updates the model $\theta^{(t)}$ based on the featurized (with featurization $F(\cdot)$) cleaned sample $F(S_{clean})$ resulting in $\theta^{(t+1)}$. Analyzing the model update procedure as a stochastic gradient descent algorithm will help derive the sampling distribution and estimation.

\vspace{0.5em}

\noindent\textbf{Estimator (Section \ref{sampling}): } The estimator approximates the optimal distribution derived in the Sample step. Based on the change in the featurized data $F(S_{clean})$ and $F(S_{dirty})$, it directs the next iteration of sampling to select points that will have changes most valuable to the next model update.


\subsection{Optimizations}
There are three aspects of \sys, that allow us to achieve this design point: error partitioning, gradient-based model update (Section \ref{model-update}), estimate-driven sampling (Section \ref{sampling}).

\vspace{0.5em}

\noindent\textbf{Partitioning Dirty and Clean Data: } In many applications, enumerating the set of corrupted records is much easier than cleaning them. For example, we may be able to select the set of rows that have missing values but actually filling those missing values is expensive. Likewise, in the constraint literature, selecting a set of rows that have a violated constraint can be done in polynomial time, however, fixing the constraints is NP-Hard.
In our error detection step, we partition the dirty and clean data.
Partitioning serves two purposes: (1) it reduces the variance of our updates because we can cheaply scan over data we know that is clean, and (2) it increases the fraction of actually dirty records in the candidate batch.
A good example of why we need the second objective is seen in the context of crowdsourcing.
If we have a crowdworker clean records, we will have to pay them for the task whether or not the record required cleaning.
To efficiently use this partitioning, we need a database solution indexing dirty and clean data.

\vspace{0.5em}

\noindent\textbf{Gradient-Based Updates: } In \sys, we start with a dirty model and then make an update using a gradient step. Here, we can draw an analogy to Materialized View maintenance, since after all, a model parametrized by $\theta$ is just a table of floating point numbers.
Krishnan et al. proposed a technique called sample view cleaning, in which they take a clean sample of data and propagate the updates to a Materialized View.
Similarly, in this work, we take the information from a sample of cleaned data and propagate an update with the gradient.

\vspace{0.5em}

\noindent\textbf{Estimate-Driven Sampling: } Repair is the most expensive step in the workflow, so optimizing for scan cost may lead to negligible overall time improvements.
We can sacrifice a small overhead in pre-computation for each data point to determine its value to the model and select a sampling distribution accordingly.
Intuitively, while each iteration has an increased cost, it also makes more progress towards the optimum.
\fi


