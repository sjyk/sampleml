\section{Introduction}
Data are susceptible to various forms of corruption such as missing, incorrect, or inconsistent representations.
Data analysts report that data cleaning is one of the most time consuming steps in the analysis process \cite{nytimes}.
Cleaning can require a significant amount of developer effort in writing software or rules to fix the corruption.
Due to this expense, there are a number of techniques to avoid cleaning entire datasets such as sampling \cite{wang1999sample}, identifying the most relevant records to queries of interest \cite{DBLP:conf/sigmod/BergmanMNT15}, and active learning \cite{gokhale2014corleone}.

These approaches are effective because they leverage knowledge about how the cleaned data will be used. 
For example, sampling may suffice when the downstream queries on the cleaned data are aggregates and active learning applies when cleaned data will be used to train a statistical model.
Active learning (see survey \cite{settles2010active}) is an increasingly popular technique to maximize the benefit of interactive data cleaning procedures \cite{DBLP:journals/pvldb/YakoutENOI11, gokhale2014corleone, yakout2013don, DBLP:journals/pvldb/HaasKWF015}.
In typical applications of active learning, the data cleaning algorithm is posed as a supervised learning problem (e.g., classify pairs of records as duplicates~\cite{gokhale2014corleone}) where humans iteratively label a small number of proposed fixes.
Active learning is a family of algorithms that prioritize supervisor input to a machine learning model in a way that maximizes the convergence rate.
The growing popularity of predictive models in data analytics \cite{bdas, alexandrov2014stratosphere, crotty2014tupleware, hellerstein2012madlib} presents a new application for active learning.
In principle, similar ideas can be applied to prioritize cleaning records that maximally affect a downstream statistical model.
In other words, this paper explores the problem of model training \emph{after} data cleaning as opposed to using a model \emph{for} data cleaning.

In broadening interactive data cleaning to also include the downstream data analysis, the key new question is statistical validity.
The analyst may query and evaluate the model \textbf{progressively} with $k \ll N$ records cleaned, and clear semantics about the accuracy of the intermediate results are needed.
Unfortunately, training a model on a mixture of dirty and clean data can lead to misleading relationships in even simple scenarios (Figure \ref{update-arch1}).
An alternative is to clean $k$ records and to disregard all of the remaining dirty records (e.g., sampling \cite{wang1999sample}).
While this avoids the mixing problem, accurate model training may require a large amount of training data and $k$ examples may not be enough for a viable model.
Furthermore, if the $k$ records are not selected uniformly at random, the trained model might be highly biased.
The errors and inefficiencies introduced by these three problems may dominate any gains from data cleaning, leading to unreliable or misleading conclusions about data or model quality.

\begin{figure}[t]
\centering
 \includegraphics[width=\columnwidth]{figs/arch.png}
 \caption{\sysfull allows users to train predictive models while progressively cleaning data. The framework adaptively selects the best data to clean and can optionally integrate with pre-defined detection rules and estimation algorithms for improved conference. \label{sys-arch}}\vspace{-2em}
\end{figure}

We present a system called \sys which applies progressive data cleaning actively while preserving the statistical validity of downstream predictive analysis.
We focus on two subproblems for a popular class of models called convex loss models (e.g., includes linear regression and SVMs): (1) the correctness problem of estimating and bounding the error in a model trained from dirty and clean data, and (2) the efficiency problem of actively selecting data to clean while preserving correctness.
We show that instead of re-training the model, the model can be incrementally maintained with gradient descent given newly cleaned data, an technique that is guaranteed to converge under suitable conditions.
Such guarantees allow analysts to trust early results during the data exploration and cleaning phase and facilitate reliable comparisons between: expensive data cleaning operations, different types of models, and different featurization techniques.

%High-dimensional predictive models are highly sensitive to dirty data.
%They rely on learning relationships between features and labels, and systematic data corruption \cite{taylor1982introduction} can mask or even introduce spurious new relationships.
%Furthermore, the high dimensionality of these models can amplify small problems \cite{xiaofeature} resulting in error-prone predictions even when trained on mostly clean data.





%When data cleaning is expensive, it is desirable to apply it \textbf{progressively}, where analysts can inspect early results with only  cleaned.
%Progressive data cleaning is a well studied problem especially in the contex of entity resolution \cite{whang2014incremental, papenbrock2015progressive, gruenheid2014incremental}.
%Increasingly, Active Learning \cite{settles2010active} or other statistical methods are applied to select records or contraint violations to clean in a way that maximizes the information gained \cite{DBLP:journals/pvldb/YakoutENOI11, gokhale2014corleone, yakout2013don}.

%Knowledge of the subsequent data analytics can also .
%While this has been explored in the context of conjuctive queries \cite{DBLP:conf/sigmod/BergmanMNT15} and SQL aggregates \cite{wang1999sample}, it is important to recognize the growing popularity of predictive models in data analytics \cite{bdas, alexandrov2014stratosphere, crotty2014tupleware, hellerstein2012madlib}.
%Predictive models rely on learning relationships between features and labels, and systematic data corruption \cite{taylor1982introduction} can mask or even introduce spurious new relationships.
%Furthermore, the high dimensionality of these models can amplify small problems \cite{xiaofeature} resulting in error-prone predictions even when trained on mostly clean data.

%Straight-forward applications of progressive data cleaning before model training can lead to .

%Suppose $k$ records are cleaned, but all of the remaining dirty records are retained in the dataset.

The \sys architecture (Figure \ref{sys-arch}) consists of a \emph{detector}, \emph{sampler}, \emph{cleaner}, \emph{update process}, and \emph{estimator}.
The cleaner is a user-provided data cleaning technique, and \sys provides the remaining components to apply the cleaner progressively.
We analyze a model where the user specifies a cleaning function $C(\cdot)$ where given any record, it returns a cleaned version of the record.
To summarize the contributions:
\begin{itemize}[noitemsep]
\item \textbf{Correctness} (Section \ref{model-update}). We show how data cleaning can be integrated with stochastic gradient descent to ensure convergence even with non-uniform samples. This update is guaranteed to converge, and for batch size $b$ and iterations $T$, converges with rate $O(\frac{1}{\sqrt{bT}})$. 
\item \textbf{Efficiency} (Section \ref{dist-samp}). We derive a theoretical optimal sampling distribution that minimizes the update error and an approximation algorithm to estimate the theoretical optimum.
\item \textbf{Detection} (Section \ref{det}). We show how \sys can be integrated with optional dirty data detection to guide data cleaning towards records expected to be dirty.
\item The experiments evaluate these components on four datasets with real and synthetic corruption (Section \ref{eval}). Results suggests that for a fixed cleaning budget, \sys returns more accurate models than uniform sampling and Active Learning when systematic corruption is sparse.

%For a 5\%  systematic corruption, \sys cleans 55\% fewer records to achieve the same accuracy as an Active Learning algorithm.
\end{itemize}






