\section{Introduction}
Data are susceptible to various forms of corruption such as missing, incorrect, or inconsistent representations \cite{Gartner}.
Dirty data can lead to inaccurate analysis, and techniques for processing dirty data are well studied \cite{rahm2000data}.
The growing popularity of predictive models in data analytics \cite{bdas, alexandrov2014stratosphere, crotty2014tupleware, hellerstein2012madlib} leads to additional challenges in managing dirty data.
Predictive models rely on learning relationships between features and labels, and systematic corruption \cite{taylor1982introduction} (i.e., corruption that disproportionately affects certain data) can mask or even introduce spurious new relationships.
Furthermore, the high dimensionality of these models can amplify small problems \cite{xiaofeature} resulting in error-prone predictions even when trained on mostly clean data.

Consider a music recommender system in which due to a software bug, all users from Europe have an incorrect age attribute defaulted to ``18-24".
A recommendation model trained on this data may spuriously learn a correlation relationship between age ``18-24" and music liked by European users.
A bug, which ostensibly affected only the European users' records, can affect predictions to all users aged ``18-24".
Systematic corruption prior to featurization is not addressed in the robust Machine Learning literature which focuses on the resilience to outliers (e.g., age ``150").

A number of data cleaning frameworks have been recently proposed to address the problem of corrupted data \cite{khayyat2015bigdansing, chu2015katara, sampleclean}.
However, data analysts report that data cleaning remains one of the most time consuming steps in the analysis process \cite{nytimes}.
Data cleaning can require a significant amount of developer effort in writing software or rules to fix the corruption.
Crowdsourcing is an increasingly popular alternative with recent success in missing value filling and entity resolution \cite{gokhale2014corleone, park2014crowdfill, sampleclean,chu2015katara}.
However, crowdsourcing comes at the cost of additional latency and the overhead of managing human workers.

When data cleaning is expensive, it is beneficial to apply it \emph{progressively}, where users can inspect early results with only $k \ll N$ records cleaned.
Progressive data cleaning allows users to specify a cleaning budget and clean until that budget is reached.
Even without a budget, progressive cleaning is useful as it allows users measure the impact of a potentially costly data cleaning operation without cleaning the entire data.
However, when applied before predictive modeling, progressive data cleaning poses several methodological problems.
Suppose $k$ records are cleaned, but all of the remaining dirty records are retained in the dataset.
Training a model on a mixture of dirty and clean data can lead to misleading relationships in even simple scenarios (Figure \ref{update-arch1}).
An alternative is to clean $k$ records and to disregard all of the remaining dirty records (e.g., sampling \cite{wang1999sample}).
While this avoids the mixing problem, accurate model training may require a large amount of training data and $k$ examples may not be enough for a viable model.
Finally, both problems are compounded by sparsity, where if corrupted records are uncommon, a random subset of $k$ records may have relatively few examples of corruptions.
The errors introduced by these three problems may dominate any gains from data cleaning, leading to unreliable or misleading conclusions about data or model quality.

\begin{figure}[t]
\centering
 \includegraphics[width=\columnwidth]{figs/arch.png}
 \caption{\sysfull is an architecture where data cleaning is integrated with model training in a framework with sampling, model update, and feedback through estimation. \label{sys-arch}}\vspace{-2em}
\end{figure}

We propose \sys, a progressive data cleaning framework, that addresses the three methodological challenges: mixing, sampling, and sparsity.
The key insight is that an important class of predictive models, called convex loss models (e.g., linear regression and SVMs), are trained by iteratively drawing random samples of data and updating a model\cite{bertsekas2011incremental}.
Rather than cleaning before model training, data cleaning can be directly integrated with the sampling and updating training process; preserving provable guarantees such as convergence and error bounds.
In \sys, data are cleaned in small random batches and the model is incrementally updated based on the results.
Similar to Active Learning, \sys selects the most valuable records to clean with higher probability, however, it applies a number of optimizations that exploit the data cleaning setting such as avoiding data that is expected to be clean, estimating of the effect of data cleaning for a record, and batching together updates from already cleaned data.
This framework is optimized for problems requiring expensive data cleaning.

The \sys architecture (Figure \ref{sys-arch}) consists of a \emph{detector}, \emph{sampler}, \emph{cleaner}, \emph{update}, and \emph{estimator}.
The cleaner is an existing data cleaning technique (e.g., Entity Resolution), and \sys provides the remaining components to apply this technique progressively.
To summarize the contributions in each component:
\begin{itemize}[noitemsep]
\item \textbf{Detector} (Section \ref{det}). The detector can apply rules from data quality constraints or adaptively learn which records are dirty to increase the fraction of dirty records sampled.
\item \textbf{Sampler} (Section \ref{dist-samp}). We derive an optimal sampling distribution that minimizes the update variance (i.e., how different would the update be if another sample was drawn) which linearly improves an error bound on the convergence rate.
\item \textbf{Update} (Section \ref{model-update}). The update procedure applies a weighted stochastic gradient descent step to the current best model. This update is guaranteed to converge, and for batch size $b$ and iterations $T$, converges with rate $O(\frac{1}{\sqrt{bT}})$. 
\item \textbf{Estimator} (Section \ref{sampling}). The estimator applies a Taylor Series linearization to decouple changes in different features to use information from error detection to inform estimation.
\item The experiments evaluate these components on four datasets with real and synthetic corruption (Section \ref{eval}). Results suggests that for a fixed cleaning budget, \sys returns more accurate models than uniform sampling and Active Learning when systematic corruption is sparse.

%For a 5\%  systematic corruption, \sys cleans 55\% fewer records to achieve the same accuracy as an Active Learning algorithm.
\end{itemize}






