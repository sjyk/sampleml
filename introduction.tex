\section{Introduction}
Large and growing data are often succeptible to various forms of corruption, or \emph{dirtiness}, such as missing, incorrect, or inconsistent values.
These corruptions can negatively affect subsequent analysis in subtle but significant ways.
While cleaning these corruptions is often highly beneficial and there are numerous established techniques, data cleaning still poses a significant analysis bottleneck \cite{khayyat2015bigdansing,sampleclean, chu2015katara}.
Cleaning large data can be expensive, both computationally and in human effort, as an analyst has to program repairs for all errors manifest in the data \cite{kandel2012}.
In some applications, simple data transformations may not be reliable necessitating the use of even costlier machine learning or crowdsourcing \cite{gokhale2014corleone,park2014crowdfill}.

To cop
